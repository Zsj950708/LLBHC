{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# require necessary packages\n",
    "from scipy import special\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, vectorize, float64, int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## object class for node\n",
    "# each node has two child branches, each of which may also be a node\n",
    "# the node contains its associated data points and the index number of cluster\n",
    "class node():\n",
    "    \"\"\"\n",
    "    The class for node.\n",
    "    Initialization requires two child branches, which may be None for end node, \n",
    "    the data points, and the index number of cluter.\n",
    "    When initialized, the node also keeps track of the number of total nodes,\n",
    "    both internal and end, within its structure as n.\n",
    "    \n",
    "    For example:\n",
    "    new_node = node(None, None, np.repeat(1,4), 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialization \n",
    "    def __init__(self, left, right, data, cnum):\n",
    "        # set up the left and right branches\n",
    "        self.l = left\n",
    "        self.r = right\n",
    "        \n",
    "        # track of number of total nodes using recursion\n",
    "        if(left == None and right == None):\n",
    "            self.n = 1\n",
    "        else:\n",
    "            self.n = left.n + right.n\n",
    "            \n",
    "        # save data points and number of cluster\n",
    "        self.data = data\n",
    "        self.cluster = cnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@jit(float64(float64[:,:], int64[:]))\n",
    "\n",
    "def p_hyp1(dataset, a):\n",
    "    \"\"\"\n",
    "    Function to calculate the posterior probability.\n",
    "    The input requires data, which is either a vector\n",
    "    or a 2D numpy array, and an alpha value, which is\n",
    "    a double\n",
    "    \"\"\"\n",
    "    \n",
    "    # extract the number of features and the total number of data\n",
    "    \n",
    "    # If the data is a vector, do the following\n",
    "    if (len(dataset.shape) == 1):\n",
    "        N = 1\n",
    "        k = dataset.shape[0]\n",
    "        # part I\n",
    "        p1 = 1\n",
    "        comp = special.gamma(np.sum(dataset)+1) / np.prod(special.gamma(dataset+1))\n",
    "        p1 = p1 * comp\n",
    "        \n",
    "        # part II\n",
    "        # iterate to calculate the probability\n",
    "        p2 = p1 * special.gamma(np.sum(a)) / special.gamma(np.sum(dataset) + np.sum(a))\n",
    "        for j in range(k):\n",
    "            comp = special.gamma(a[j] + np.sum(dataset[j])) / special.gamma(a[j])\n",
    "            p2 = p2 * comp\n",
    "    # if the data is not vector, do the following\n",
    "    else:\n",
    "        N = dataset.shape[0]\n",
    "        k = dataset.shape[1]\n",
    "    \n",
    "        # part I\n",
    "        p1 = 1\n",
    "        for i in range(N):\n",
    "            comp = special.gamma(np.sum(dataset[i, :])+1) / np.prod(special.gamma(dataset[i, :]+1))\n",
    "            p1 = p1 * comp\n",
    "        \n",
    "        # part II\n",
    "        # iterate to calculate the probability\n",
    "        p2 = p1 * special.gamma(np.sum(a)) / special.gamma(np.sum(dataset) + np.sum(a))\n",
    "        for j in range(k):\n",
    "            comp = special.gamma(a[j] + np.sum(dataset[:, j])) / special.gamma(a[j])\n",
    "            p2 = p2 * comp\n",
    "\n",
    "    return p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_d(node, a):\n",
    "    \"\"\"\n",
    "    Recursive function to calculate the 'd' value for each node\n",
    "    \n",
    "    \"\"\"\n",
    "    if node.l == None and node.r == None:\n",
    "        return a\n",
    "    else:\n",
    "        return a*special.gamma(node.n) + get_d(node.l, a)*get_d(node.r, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pi(node, a):\n",
    "    \"\"\"\n",
    "    The function to calculate the weight for each node (pi_k).\n",
    "    It uses d and the gamma function.\n",
    "    The inputs are a node object and a double\n",
    "    \"\"\"\n",
    "    dk = get_d(node, a)\n",
    "    pi_k = a*special.gamma(node.n)/dk\n",
    "    return pi_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dk(node, a):\n",
    "    \"\"\"\n",
    "    The Recursive function to calculate the posterior probability for\n",
    "    each node given a subtree (Ti).\n",
    "    The inputs are a node and a double\n",
    "    \"\"\"\n",
    "    post = p_hyp1(node.data, np.repeat(a, node.data.shape[1]))\n",
    "    pi = get_pi(node, a)\n",
    "    if node.l == None and node.r == None:\n",
    "        return  pi * post\n",
    "    else:\n",
    "        return  pi * post + (1-pi) * get_dk(node.l, a) * get_dk(node.r, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1, 0, 0, 0],\n",
       "       [2, 0, 2, 3, 1],\n",
       "       [1, 3, 1, 3, 3],\n",
       "       [0, 3, 1, 1, 3],\n",
       "       [0, 1, 3, 2, 2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## simulated test data\n",
    "sdata = np.random.randint(0,4, size=(5,5))\n",
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"wine.csv\") as f:\n",
    "    next(f)\n",
    "    text = f.read() \n",
    "\n",
    "data = []\n",
    "lines  = text.split('\\n')\n",
    "for line in lines[:-1]:\n",
    "    arr = line.split(';')\n",
    "    fl = [int(np.round(float(x))) for x in arr]\n",
    "    data.append(fl)\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  1,  0,  2,  0],\n",
       "       [ 8,  1,  0,  3,  0],\n",
       "       [ 8,  1,  0,  2,  0],\n",
       "       [11,  0,  1,  2,  0],\n",
       "       [ 7,  1,  0,  2,  0],\n",
       "       [ 7,  1,  0,  2,  0],\n",
       "       [ 8,  1,  0,  2,  0],\n",
       "       [ 7,  1,  0,  1,  0],\n",
       "       [ 8,  1,  0,  2,  0],\n",
       "       [ 8,  0,  0,  6,  0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data from wine.csv\n",
    "tdata = data[:10,:5]\n",
    "tdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bhc(data, a=1, r_thres=0.5):\n",
    "    \"\"\"\n",
    "    The Baysian Hierarchical Clustering algorithm.\n",
    "    It is described in the paper collaborated by\n",
    "    Dr. Katherine Heller and Dr. Zoubin Ghahramani\n",
    "    in 2005.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a node_list tracking the nodes to be merged\n",
    "    # and a node_list_copy to track the cluster number of each\n",
    "    # node. The initial value of those two lists are each data\n",
    "    # points with its own cluster number.\n",
    "    node_list = []\n",
    "    node_list_copy = []\n",
    "    for i in range(data.shape[0]):\n",
    "        node_list.append(node(None, None, np.array([data[i,:]]), i))\n",
    "        node_list_copy.append(node(None, None, np.array([data[i,:]]), i))\n",
    "    \n",
    "    # Cluster number, default value equals the number of data points\n",
    "    c = data.shape[0]\n",
    "    \n",
    "    # Iterate to merge nodes. Note that BHC is a greedy algorithm, which means\n",
    "    # if no tow nodes can be merged, the loop stops automatically\n",
    "    while c > 1:\n",
    "        flag = False\n",
    "        \n",
    "        for i in range(len(node_list)):\n",
    "            for j in range(i+1, len(node_list)):\n",
    "                \n",
    "                newdata = np.concatenate((node_list[i].data, node_list[j].data), axis = 0)\n",
    "                \n",
    "                node_new = node(node_list[i], node_list[j], newdata, min(node_list[i].cluster,node_list[j].cluster))\n",
    "                pi_k = get_pi(node_new, a)\n",
    "                print(pi_k)\n",
    "                p_hyp = p_hyp1(node_new.data, np.repeat(a, data.shape[1]))\n",
    "                print(p_hyp)\n",
    "                p_dk = get_dk(node_new, a)\n",
    "                print(p_dk)\n",
    "                rk = pi_k * p_hyp / p_dk\n",
    "                print(rk)\n",
    "                if rk >= r_thres:\n",
    "                    for k in range(len(node_list_copy)):\n",
    "                        entry = node_list_copy[k].cluster\n",
    "                        if entry == node_list[i].cluster or entry == node_list[j].cluster:\n",
    "                            node_list_copy[k].cluster = min(node_list[i].cluster,node_list[j].cluster)\n",
    "                    node_list =  node_list[:i] + node_list[(i+1):j] + node_list[(j+1):]\n",
    "                    node_list = [node_new] + node_list\n",
    "                    \n",
    "                    c = c - 1\n",
    "                    flag = True\n",
    "                    break\n",
    "            if flag == True:\n",
    "                break\n",
    "        \n",
    "        if flag == False:\n",
    "            c = 1        \n",
    "\n",
    "    return node_list, node_list_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "1.33128414189e-05\n",
      "5.15232463476e-10\n",
      "12919.2571923\n",
      "0.5\n",
      "4.80976074773e-07\n",
      "2.07134316484e-12\n",
      "116102.460214\n",
      "0.6\n",
      "3.83213331073e-09\n",
      "2.52372357587e-15\n",
      "911066.492553\n",
      "0.705882352941\n",
      "2.1018439599e-10\n",
      "5.05059038668e-17\n",
      "2937586.39355\n",
      "0.779220779221\n",
      "1.30712986589e-11\n",
      "1.27229338988e-18\n",
      "8005565.07439\n",
      "0.823798627002\n",
      "8.35393751282e-13\n",
      "3.29605358114e-20\n",
      "20879400.4215\n",
      "0.852215082854\n",
      "6.60479493437e-14\n",
      "1.34267571441e-21\n",
      "41921558.585\n",
      "0.872085478219\n",
      "4.82785695329e-15\n",
      "4.66294650314e-23\n",
      "90292778.119\n",
      "0.886989934346\n",
      "4.18770573233e-17\n",
      "1.72582164001e-25\n",
      "215228083.045\n"
     ]
    }
   ],
   "source": [
    "# test when the threshold for rk is 0 and alpha = 1\n",
    "node_list, node_list_cluster = bhc(tdata, a=1, r_thres=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[node.cluster for node in node_list_cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 7,  1,  0,  2,  0],\n",
       "        [ 8,  1,  0,  3,  0],\n",
       "        [ 8,  1,  0,  2,  0],\n",
       "        [11,  0,  1,  2,  0],\n",
       "        [ 7,  1,  0,  2,  0],\n",
       "        [ 7,  1,  0,  2,  0],\n",
       "        [ 8,  1,  0,  2,  0],\n",
       "        [ 7,  1,  0,  1,  0],\n",
       "        [ 8,  1,  0,  2,  0],\n",
       "        [ 8,  0,  0,  6,  0]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[node.data for node in node_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 1 0 2 0]\n",
      " [8 1 0 3 0]]\n",
      "12919.2571923\n",
      "[[7 1 0 2 0]\n",
      " [8 1 0 3 0]\n",
      " [8 1 0 2 0]]\n",
      "116102.460214\n",
      "[[ 7  1  0  2  0]\n",
      " [ 8  1  0  3  0]\n",
      " [ 8  1  0  2  0]\n",
      " [11  0  1  2  0]]\n",
      "911066.492553\n",
      "[[ 7  1  0  2  0]\n",
      " [ 8  1  0  3  0]\n",
      " [ 8  1  0  2  0]\n",
      " [11  0  1  2  0]\n",
      " [ 7  1  0  2  0]]\n",
      "2937586.39355\n",
      "[[ 7  1  0  2  0]\n",
      " [ 8  1  0  3  0]\n",
      " [ 8  1  0  2  0]\n",
      " [11  0  1  2  0]\n",
      " [ 7  1  0  2  0]\n",
      " [ 7  1  0  2  0]]\n",
      "8005565.07439\n",
      "[[ 7  1  0  2  0]\n",
      " [ 8  1  0  3  0]\n",
      " [ 8  1  0  2  0]\n",
      " [11  0  1  2  0]\n",
      " [ 7  1  0  2  0]\n",
      " [ 7  1  0  2  0]\n",
      " [ 8  1  0  2  0]]\n",
      "20879400.4215\n",
      "[[ 7  1  0  2  0]\n",
      " [ 8  1  0  3  0]\n",
      " [ 8  1  0  2  0]\n",
      " [11  0  1  2  0]\n",
      " [ 7  1  0  2  0]\n",
      " [ 7  1  0  2  0]\n",
      " [ 8  1  0  2  0]\n",
      " [ 7  1  0  1  0]]\n",
      "41921558.585\n",
      "[[ 7  1  0  2  0]\n",
      " [ 8  1  0  3  0]\n",
      " [ 8  1  0  2  0]\n",
      " [11  0  1  2  0]\n",
      " [ 7  1  0  2  0]\n",
      " [ 7  1  0  2  0]\n",
      " [ 8  1  0  2  0]\n",
      " [ 7  1  0  1  0]\n",
      " [ 8  1  0  2  0]]\n",
      "90292778.119\n",
      "[[ 7  1  0  2  0]\n",
      " [ 8  1  0  3  0]\n",
      " [ 8  1  0  2  0]\n",
      " [11  0  1  2  0]\n",
      " [ 7  1  0  2  0]\n",
      " [ 7  1  0  2  0]\n",
      " [ 8  1  0  2  0]\n",
      " [ 7  1  0  1  0]\n",
      " [ 8  1  0  2  0]\n",
      " [ 8  0  0  6  0]]\n",
      "215228083.045\n"
     ]
    }
   ],
   "source": [
    "# test when the threshold for rk is 1 and alpha = 1\n",
    "nodes, nodes_cluster = bhc(tdata, a=1, r_thres=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[node.cluster for node in nodes_cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 7,  1,  0,  2,  0],\n",
       "        [ 8,  1,  0,  3,  0],\n",
       "        [ 8,  1,  0,  2,  0],\n",
       "        [11,  0,  1,  2,  0],\n",
       "        [ 7,  1,  0,  2,  0],\n",
       "        [ 7,  1,  0,  2,  0],\n",
       "        [ 8,  1,  0,  2,  0],\n",
       "        [ 7,  1,  0,  1,  0],\n",
       "        [ 8,  1,  0,  2,  0],\n",
       "        [ 8,  0,  0,  6,  0]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[node.data for node in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
